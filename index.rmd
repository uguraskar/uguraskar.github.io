---
author: "Uğur Aşkar"
output:
  html_document:
    code_folding: hide
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: false
    number_sections: false
---

# Work Experience

**Data Engineer** *Union Bilgi Teknolojileri A.Ş.* <small>2021/01-Current</small>

 * Consulting a Leading Global FMCG company and giving technical advice
 * Analyzed and then effectively strategized in regard to business goals, deadlines, schedules, needed resources
 * Handled, prioritized, and problem-solved multiple tasks connected to multiple projects at one time
 * Developing ETL Jobs with SQL Server Integration Services and C# Scripts
 * Creating data models with SQL Server Analysis Services
 * Designing dashboards with data visualization with Power BI
 * Created Jobs that imported data from APIs in JSON and XML format, FTP, Sharepoint, Excel and Databases

**Business Intelligence Expert** *Aegon Emeklilik ve Hayat* <small>2020/12</small>

 * Meet the needs of business units with Ad-Hoc Report Designs.
 * Analyzing the needs of business units and creating report continuity
 * Checking ETL in daily periods.
 * Analyzing and managing requests on request management system.
 * Giving permission to view or hide datasets from certain unit(s) or people under Turkish Personal Data Protection Law

**Business Intelligence & Data Analyst Junior Engineer** *Cigna Finans Emeklilik ve Hayat A.Ş* <small>2019/06-2020/11</small>

 * Meet the needs of business units with Ad-Hoc Report Designs.
 * Improving system architecture with Universe Adjustments
 * Designing dashboards with data visualization
 * Analyzing the needs of business units and creating report continuity
 * Creating data models and data architecture.
 * Managing data flow’s lifecycle
 * Checking ETL in daily periods.
 * Analyzing and managing requests on request management system.
 * Managing system infrastructure of SAP Business Object
 * Creating WEBI users and authorizing them
 * Giving permission to view or hide datasets from certain unit(s) or people under Turkish Personal Data Protection Law
 * Creating Data Flow, Work Flow and Jobs.
 * Creating and execution of ETL Transforms
 * Developing SAP Data Services (BODS) Jobs, workflows and dataflows for data warehouse implementation.
 * Using different data sources as MSSQL Server, Oracle Database, FTP and Excel to gather data and implementing them.
 * Developing PL/SQL functions for data warehouse implementations.
 * Improving/Optimizing detailed SQL Queries.
 * Optimization of ETL Jobs.
 * Fixing ETL Errors and inconsistent data and Improving BI Implementations.
 * Creating reusable SQL Queries to clean, manipulate and analyzing data.
 * Consulting about BI Tools to maintain and upgrade them.
 * Managing system infrastructure to create data transfers from new sources.
 * Managing architecture and development process under our company standards.
 * Detecting software errors and technical solutions about them.
 * Consulting other team members about SQL Optimization and giving technical advices.
 * Creating end to end report solutions

**Junior Information Technology & Operations** *VHV Reasürans* <small>2018/04-2018/05</small>

I worked in the Information Technology & Operations department of the company operating in the Insurance/Reinsurance sector and supported the Claims Department. Since the company was of foreign origin, English was spoken frequently.

Tools I worked with:

 * SICS
 * SAP Business Objects
 * Microsoft Visio

**Internship** *FSD Yazılım Bilişim Hizmetleri* <small>2016/08-2016/09</small>

 * .NET Front-end Web development
 * WinForms
 * MSSQL
 * Photoshop

**Internship** *Ray Business Solutions* <small>2016/07-2016/08</small>

.NET Software Developer Intern at Arçelik

**Internship** *Cigna Finans Emeklilik ve Hayat A.Ş* <small>2012/07-2012/08</small>

I worked in the IT department of the company operating in the insurance sector to help with hardware inventory management and software and hardware problems faced by users.

**Internship** *Cigna Finans Emeklilik ve Hayat A.Ş* <small>2011/07</small>

I worked in the IT department of the company operating in the insurance sector to help with hardware inventory management and software and hardware problems faced by users.

# Education

**Big Data Analysis** ![](images/MEF.png "MEF University"){width=4%} *MEF University* <small>2020-</small>

**Business Administration / Management** ![](images/Anadolu.png "Anadolu University"){width=2.5%} *Anadolu University* <small>2019-</small>

**Electronics and Communication Engineering** ![](images/BEU.png "Beykent University"){width=2.5%} *Beykent University* <small>2014-2019</small>

Double Major

**Software Engineering** ![](images/BEU.png "Beykent University"){width=2.5%} *Beykent University* <small>2013-2017</small>

I became top scoring student in 2013-2014 and claimed scholarship.

Succeeded at Oxford English Exam organized by Beykent University and exempted from preparatory class. My level was determined as C2 at the exam.

# Projects

## [Foodbasket](https://uguraskar.github.io/foodbasket/foodbasket "Foodbasket") ![](images/python.png "Python"){width=2.5%} ![](images/postgresql.png "PostgreSQL"){width=2.5%} <small>2021/01</small>

In this project, sentiment analysis methods are used to predict and improve online customer feedbacks about fast food restaurants. In order to gather data, web scrapping methods were used on the biggest online food delivery service in Turkey. Natural language processing methods such as text lemmatization, stopword removal, porter stemmer, word normalization, word frequency methods such as TF-IDF and Count Vectorizer are used. After text preprocessing methods are used, sentiment scores are created by matching words in the comments given by users. Gradient Boosting Machines are used primarily as model in the project such as LightGBM. Performance of the project are evaluated by using mean squared errors and R-squared values.

People tend to give their reviews in extreme values, for this reason it would be preferable to train the model using scores while creating a sentiment-based model in the end. With this method there would be more smooth transition in scores and each customers true feelings towards to product can be extracted from the review itself.

We observe that; customers were mainly satisfied with restaurants which had expensive products, higher variety of products and higher sentiment scores. It is not possible do dive deeper to expensive products part due to this project was focusing mainly on making analysis using machine learning approach. However it could be caused by higher quality of the ingredients or customers deeming expensive restaurants a royalty and scoring based on it.

## Prophet ![](images/python.png "Python"){width=2.5%} ![](images/postgresql.png "PostgreSQL"){width=2.5%} <small>2021/06</small>

While data and results are confidential to talk about, in this project data was owned by a leading global FMCG company and one of its distributors. Clustering and regression machine learning algorithms were used.

## [Reddit Analysis](https://uguraskar.github.io/reddit_analysis/reddit_analysis.html "Reddit Analysis") ![](images/python.png "Python"){width=2.5%} ![](images/postgresql.png "PostgreSQL"){width=2.5%} <small>2021/01</small>

It is a project given by MEF University - Big Data Analytics - Introduction to Computer Programming(Python) class.

Our aim here is to work with big datasets and replicate data management tools in python while doing data analysis. We will combine python with sql because pandas dataframe only works in memory and our dataset is much bigger than our memory can handle. In some of the parts we are going to touch some Natural Language Proccessing libraries and make our dataset smaller and detect languages in comments.

Finally we are going to estimate how much profit we can make from smart ads like google's adsense if we implemented one in this certain website.

Working with big datasets are always a huge challenge and it gives us new opportunities to improve.

## [Foursquare Analysis](https://uguraskar.github.io/foursquare_analysis/foursquare_analysis.html "Foursquare Analysis") ![](images/python.png "Python"){width=2.5%} ![](images/postgresql.png "PostgreSQL"){width=2.5%} <small>2021/01</small>

It is a group project given by MEF University - Big Data Analytics - Big Data Management class.

Exploratory analysis about Foursquare where users can share their locations and rate venues. This dataset contains 09/2013's values.

## [High Frequency Trading](https://uguraskar.github.io/High-Frequency-Trading/ "High Frequency Trading") ![](images/R.png "R"){width=2.5%} <small>2021/01</small>

It is a mini-project given by MEF University - Big Data Analytics - Applied Statistics.

High-frequency trading(HFT) is a financial innovation which was enabled by recent high performance computing, some of the transactions can be even made in microseconds.

In this analysis we are trying to replicate and share our research about it.

## [Querying the IMDB Database](https://github.com/uguraskar/Querying-the-IMDB-Database/blob/main/Querying-the-IMDB-Database.ipynb "Querying the IMDB Database") ![](images/postgresql.png "PostgreSQL"){width=2.5%} <small>2020/12</small>

It is a mini-project given by MEF University - Big Data Analytics - Big Data Management class, we do use [binder repositories](https://notebooks.gesis.org/binder/v2/gh/serhatcevikel/bdm_2019/hadoop "Serhat Çevikel's binder") instead of working on local. 

Binder has some advantages compared to other systems, you can use bash, R, python etc. in same binder without changing the notebook.

It uses postgresql as database and main goal here is to use;

 * Subqueries
 * Having Clauses
 * Window Functions
 * Common Term Expressions
 * Joins
 * Indexing

## Health Insurance ![](images/Oracle.png "Oracle"){width=4%} ![](images/SAP.png "SAP"){width=3.5%} <small>2020</small>

Infrastructure work for incoming health insurance system.

## Agito System Integration ![](images/Oracle.png "Oracle"){width=4%} ![](images/SAP.png "SAP"){width=3.5%} <small>2019-2020</small>

 * Creating data maps and integrating data from new system.
 * Creating DataWareHouse data flows from new system.
 * Creating DataMarts.
 * Merging data with current system.

## Collection Performance - Vintage ![](images/Oracle.png "Oracle"){width=4%} ![](images/SAP.png "SAP"){width=3.5%} <small>2020</small>

 * Report itself evaluetes company’s sales/collection and accounting performance.
 * Transformed data size is around 350GB.
 * Used PL/SQL and BODS.
 * High degree of accuracy and precision.
 * Created new datamart.

## IFRS 17 ![](images/Oracle.png "Oracle"){width=4%} ![](images/SAP.png "SAP"){width=3.5%} <small>2019-2020</small>

Insurance policy

Implementing IFRS 17(International Financial Reporting Standart) that is issued for accounting insurance contracts and will have effective date of 2023.

## [Covid Tracker](https://github.com/uguraskar/covid-tracker "Covid Tracker") ![](images/python.png "Python"){width=2.5%} <small>2020/05</small>

It gathers global covid-19 cases from github page as data provider, and exports it as a excel file.

## Social Media & Datamining ![](images/CSharp.png "C#"){width=2.5%} ![](images/JavaScript.png "JavaScript"){width=2.5%} <small>2016/10-2017/06</small>

Used languages and Technologies: 

 * C# WinForms 
 * Javascript 
 * PHP 
 * MSSQL Stored Procedure 
 * HTML

Used user datasets from Foursquare/Swarm API in JSON format and transformed it. Transformed data could be used for smart ads or security concerns.

Google maps javascript API used to visualize data. Used data encryption functions and methods to encrypt data. Used pushover and pushbullet API’s to send visualized data to smartphones. 

Project Documentation created with; 

 * IEEE SRS(System Requirements Specifications) 
 * IEEE STD(System Test Documentation) 
 * IEEE SDD(Software Design Documentation)

standarts.